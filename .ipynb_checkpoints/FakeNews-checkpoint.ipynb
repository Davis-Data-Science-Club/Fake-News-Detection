{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9253f17c-9629-4ce3-a4c5-d1bf227ea7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olivia/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b0719d-8c58-4d98-802b-26ed1347a4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|███████████████████████████████| 6.41k/6.41k [00:00<00:00, 1.37MB/s]\n",
      "Downloading metadata: 100%|██████████████████████████████████████| 4.03k/4.03k [00:00<00:00, 757kB/s]\n",
      "Downloading readme: 100%|████████████████████████████████████████| 5.16k/5.16k [00:00<00:00, 680kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset liar/default to /Users/olivia/.cache/huggingface/datasets/liar/default/1.0.0/479463e757b7991eed50ffa7504d7788d6218631a484442e2098dabbf3b44514...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|█████████████████████████████████████████| 1.01M/1.01M [00:00<00:00, 6.65MB/s]\n",
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset liar downloaded and prepared to /Users/olivia/.cache/huggingface/datasets/liar/default/1.0.0/479463e757b7991eed50ffa7504d7788d6218631a484442e2098dabbf3b44514. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 369.33it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"liar\") #loading from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7825c6e-f522-4126-be12-8b2befb09329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-de190e5a0ef0d227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /Users/olivia/.cache/huggingface/datasets/csv/default-de190e5a0ef0d227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████████████████████████| 1/1 [00:00<00:00, 2468.69it/s]\n",
      "Extracting data files: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00, 536.22it/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]/Users/olivia/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /Users/olivia/.cache/huggingface/datasets/csv/default-de190e5a0ef0d227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 282.71it/s]\n"
     ]
    }
   ],
   "source": [
    "fake_csv = load_dataset(\"csv\", data_files=\"news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc8ab84-38fe-42a7-99fd-e9c0227b363c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
       "        num_rows: 6335\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f2a08f-9449-4784-b4b8-bd2315aaa8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_csv_split = fake_csv[\"train\"].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "121a7fda-1055-4886-a2a1-f36d5e54d451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
       "        num_rows: 5701\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
       "        num_rows: 634\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_csv_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8895849-bc68-461e-af57-cf9bc73c0d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|████████████████████████| 28.0/28.0 [00:00<00:00, 4.93kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████████████████████| 483/483 [00:00<00:00, 55.3kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|█████████████████████████| 232k/232k [00:00<00:00, 930kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|█████████████████████████| 466k/466k [00:00<00:00, 869kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load DistilBERT tokenizer and tokenize (encode) the texts\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1abd28d6-b0f1-49f0-905a-9e1f1171435a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 5701/5701 [00:00<00:00, 9964.76ex/s]\n",
      "100%|███████████████████████████████████████████████████████████| 634/634 [00:00<00:00, 16909.40ex/s]\n"
     ]
    }
   ],
   "source": [
    "fake_csv_split = fake_csv_split.map(lambda x: {\"label\": 1 if x[\"label\"] == \"FAKE\" else 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d58f97e3-e6b0-481f-9452-94d3079c5042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/olivia/opt/anaconda3/envs/fakenews\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    future-0.18.2              |  py310hca03da5_1         656 KB\n",
      "    libopenblas-0.3.21         |       h269037a_0         3.3 MB\n",
      "    ninja-1.10.2               |       hca03da5_5           9 KB\n",
      "    ninja-base-1.10.2          |       h525c30c_5         108 KB\n",
      "    openssl-1.1.1s             |       h1a28f6b_0         3.1 MB\n",
      "    pytorch-1.12.1             |cpu_py310h6ba7f14_0        38.5 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        45.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  future             pkgs/main/osx-arm64::future-0.18.2-py310hca03da5_1 \n",
      "  libopenblas        pkgs/main/osx-arm64::libopenblas-0.3.21-h269037a_0 \n",
      "  ninja              pkgs/main/osx-arm64::ninja-1.10.2-hca03da5_5 \n",
      "  ninja-base         pkgs/main/osx-arm64::ninja-base-1.10.2-h525c30c_5 \n",
      "  pytorch            pkgs/main/osx-arm64::pytorch-1.12.1-cpu_py310h6ba7f14_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  openssl            pkgs/main/osx-64::openssl-1.1.1s-hca7~ --> pkgs/main/osx-arm64::openssl-1.1.1s-h1a28f6b_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "future-0.18.2        | 656 KB    |                                       |   0% \n",
      "ninja-1.10.2         | 9 KB      |                                       |   0% \u001b[A\n",
      "\n",
      "libopenblas-0.3.21   | 3.3 MB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ninja-base-1.10.2    | 108 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "future-0.18.2        | 656 KB    | 9                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libopenblas-0.3.21   | 3.3 MB    | 1                                     |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ninja-base-1.10.2    | 108 KB    | #####4                                |  15% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ninja-base-1.10.2    | 108 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "future-0.18.2        | 656 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    | ##9                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "ninja-1.10.2         | 9 KB      | ##################################### | 100% \u001b[A\n",
      "ninja-1.10.2         | 9 KB      | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libopenblas-0.3.21   | 3.3 MB    | #####7                                |  15% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    | #####5                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | 5                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libopenblas-0.3.21   | 3.3 MB    | ########8                             |  24% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    | ########6                             |  23% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | #                                     |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libopenblas-0.3.21   | 3.3 MB    | #############3                        |  36% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    | ###########2                          |  30% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | #3                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libopenblas-0.3.21   | 3.3 MB    | #################3                    |  47% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    | ##############3                       |  39% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | #8                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libopenblas-0.3.21   | 3.3 MB    | ######################                |  60% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    | #################8                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libopenblas-0.3.21   | 3.3 MB    | ###########################5          |  75% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ##1                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    | ####################7                 |  56% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libopenblas-0.3.21   | 3.3 MB    | #################################1    |  90% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ##5                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    | #######################9              |  65% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ##9                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    | #############################         |  79% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libopenblas-0.3.21   | 3.3 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ###5                                  |  10% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    | ################################7     |  89% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ####1                                 |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1s       | 3.1 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ####7                                 |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | #####5                                |  15% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ######1                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ######9                               |  19% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ########                              |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ########8                             |  24% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ##########3                           |  28% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ###########3                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ############5                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | #############6                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ##############9                       |  40% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ################3                     |  44% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | #################5                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ###################                   |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ####################4                 |  55% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | #####################6                |  59% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | #######################3              |  63% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ########################6             |  67% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ##########################            |  70% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ###########################3          |  74% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ############################9         |  78% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ##############################3       |  82% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ###############################8      |  86% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | #################################4    |  90% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ###################################   |  95% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch-1.12.1       | 38.5 MB   | ####################################3 |  98% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -y pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4864fef9-9f5b-470f-86e8-79fb700f97d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/olivia/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/torch/lib/libtorch_global_deps.dylib, 0x000A): tried: '/Users/olivia/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/torch/lib/libtorch_global_deps.dylib' (mach-o file, but is an incompatible architecture (have (arm64), need (x86_64)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/torch/__init__.py:201\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;66;03m# Easy way.  You want this most of the time, because it will prevent\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# C++ symbols from libtorch clobbering C++ symbols from other\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# See Note [Global dependencies]\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[0;32m--> 201\u001b[0m         \u001b[43m_load_global_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# torch._C module initialization code in C\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/torch/__init__.py:154\u001b[0m, in \u001b[0;36m_load_global_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m here \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18m__file__\u001b[39m)\n\u001b[1;32m    152\u001b[0m lib_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(here), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlib\u001b[39m\u001b[38;5;124m'\u001b[39m, lib_name)\n\u001b[0;32m--> 154\u001b[0m \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlib_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRTLD_GLOBAL\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/ctypes/__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/olivia/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/torch/lib/libtorch_global_deps.dylib, 0x000A): tried: '/Users/olivia/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/torch/lib/libtorch_global_deps.dylib' (mach-o file, but is an incompatible architecture (have (arm64), need (x86_64)))"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dfcfa2b-019b-4a0a-a7cf-b3235c72b840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/olivia/.cache/huggingface/datasets/csv/default-de190e5a0ef0d227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-0891c8eed67879d3.arrow\n",
      "Loading cached processed dataset at /Users/olivia/.cache/huggingface/datasets/csv/default-de190e5a0ef0d227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-b62377723cd56423.arrow\n",
      "Loading cached processed dataset at /Users/olivia/.cache/huggingface/datasets/csv/default-de190e5a0ef0d227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-23a8a0bfe61588f8.arrow\n",
      "Loading cached processed dataset at /Users/olivia/.cache/huggingface/datasets/csv/default-de190e5a0ef0d227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-ea752877973f35a9.arrow\n",
      "Loading cached processed dataset at /Users/olivia/.cache/huggingface/datasets/csv/default-de190e5a0ef0d227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-636477d8a63d9985.arrow\n",
      "Loading cached processed dataset at /Users/olivia/.cache/huggingface/datasets/csv/default-de190e5a0ef0d227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-146233e0f84d34cf.arrow\n",
      "Loading cached processed dataset at /Users/olivia/.cache/huggingface/datasets/csv/default-de190e5a0ef0d227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-78f88005370443a7.arrow\n",
      "Loading cached processed dataset at /Users/olivia/.cache/huggingface/datasets/csv/default-de190e5a0ef0d227/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-3c003ebecc0c8bce.arrow\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "PyTorch needs to be installed to be able to return PyTorch tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m dataset_enc \u001b[38;5;241m=\u001b[39m fake_csv_split\u001b[38;5;241m.\u001b[39mmap(tokenize, remove_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_proc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Set dataset format for PyTorch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdataset_enc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtorch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Check the output\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset_enc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumn_names)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/datasets/dataset_dict.py:548\u001b[0m, in \u001b[0;36mDatasetDict.set_format\u001b[0;34m(self, type, columns, output_all_columns, **format_kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_values_type()\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 548\u001b[0m     \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mformat_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/datasets/fingerprint.py:480\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    478\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/datasets/arrow_dataset.py:2315\u001b[0m, in \u001b[0;36mDataset.set_format\u001b[0;34m(self, type, columns, output_all_columns, **format_kwargs)\u001b[0m\n\u001b[1;32m   2313\u001b[0m \u001b[38;5;66;03m# Check that the format_type and format_kwargs are valid and make it possible to have a Formatter\u001b[39;00m\n\u001b[1;32m   2314\u001b[0m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m get_format_type_from_alias(\u001b[38;5;28mtype\u001b[39m)\n\u001b[0;32m-> 2315\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mformat_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;66;03m# Check filter column\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(columns, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/datasets/formatting/__init__.py:127\u001b[0m, in \u001b[0;36mget_formatter\u001b[0;34m(format_type, **format_kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _FORMAT_TYPES[format_type](\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_type \u001b[38;5;129;01min\u001b[39;00m _FORMAT_TYPES_ALIASES_UNAVAILABLE:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _FORMAT_TYPES_ALIASES_UNAVAILABLE[format_type]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn type should be None or selected in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mtype\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _FORMAT_TYPES\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformat_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m dataset_enc \u001b[38;5;241m=\u001b[39m fake_csv_split\u001b[38;5;241m.\u001b[39mmap(tokenize, remove_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_proc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Set dataset format for PyTorch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdataset_enc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtorch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Check the output\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset_enc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumn_names)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/datasets/dataset_dict.py:548\u001b[0m, in \u001b[0;36mDatasetDict.set_format\u001b[0;34m(self, type, columns, output_all_columns, **format_kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_values_type()\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 548\u001b[0m     \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mformat_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/datasets/fingerprint.py:480\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    478\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/datasets/arrow_dataset.py:2315\u001b[0m, in \u001b[0;36mDataset.set_format\u001b[0;34m(self, type, columns, output_all_columns, **format_kwargs)\u001b[0m\n\u001b[1;32m   2313\u001b[0m \u001b[38;5;66;03m# Check that the format_type and format_kwargs are valid and make it possible to have a Formatter\u001b[39;00m\n\u001b[1;32m   2314\u001b[0m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m get_format_type_from_alias(\u001b[38;5;28mtype\u001b[39m)\n\u001b[0;32m-> 2315\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mformat_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;66;03m# Check filter column\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(columns, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/datasets/formatting/__init__.py:127\u001b[0m, in \u001b[0;36mget_formatter\u001b[0;34m(format_type, **format_kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _FORMAT_TYPES[format_type](\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_type \u001b[38;5;129;01min\u001b[39;00m _FORMAT_TYPES_ALIASES_UNAVAILABLE:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _FORMAT_TYPES_ALIASES_UNAVAILABLE[format_type]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn type should be None or selected in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mtype\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _FORMAT_TYPES\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformat_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping similar frames: <module> at line 9 (1 times), get_formatter at line 127 (1 times), InteractiveShell.run_code at line 3442 (1 times), DatasetDict.set_format at line 548 (1 times), Dataset.set_format at line 2315 (1 times), fingerprint_transform.<locals>._fingerprint.<locals>.wrapper at line 480 (1 times)]\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m dataset_enc \u001b[38;5;241m=\u001b[39m fake_csv_split\u001b[38;5;241m.\u001b[39mmap(tokenize, remove_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_proc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Set dataset format for PyTorch\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdataset_enc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtorch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Check the output\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset_enc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumn_names)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/datasets/dataset_dict.py:548\u001b[0m, in \u001b[0;36mDatasetDict.set_format\u001b[0;34m(self, type, columns, output_all_columns, **format_kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_values_type()\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 548\u001b[0m     \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mformat_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/datasets/fingerprint.py:480\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    478\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/datasets/arrow_dataset.py:2315\u001b[0m, in \u001b[0;36mDataset.set_format\u001b[0;34m(self, type, columns, output_all_columns, **format_kwargs)\u001b[0m\n\u001b[1;32m   2313\u001b[0m \u001b[38;5;66;03m# Check that the format_type and format_kwargs are valid and make it possible to have a Formatter\u001b[39;00m\n\u001b[1;32m   2314\u001b[0m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m get_format_type_from_alias(\u001b[38;5;28mtype\u001b[39m)\n\u001b[0;32m-> 2315\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mformat_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;66;03m# Check filter column\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(columns, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fakenews/lib/python3.10/site-packages/datasets/formatting/__init__.py:127\u001b[0m, in \u001b[0;36mget_formatter\u001b[0;34m(format_type, **format_kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _FORMAT_TYPES[format_type](\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_type \u001b[38;5;129;01min\u001b[39;00m _FORMAT_TYPES_ALIASES_UNAVAILABLE:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _FORMAT_TYPES_ALIASES_UNAVAILABLE[format_type]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn type should be None or selected in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mtype\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _FORMAT_TYPES\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformat_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: PyTorch needs to be installed to be able to return PyTorch tensors."
     ]
    }
   ],
   "source": [
    "# Tokenize and encode the dataset\n",
    "def tokenize(batch):\n",
    "    tokenized_batch = tokenizer(batch['text'], padding=True, truncation=True, max_length=128)\n",
    "    return tokenized_batch\n",
    "\n",
    "dataset_enc = fake_csv_split.map(tokenize, remove_columns=['Unnamed: 0', 'title', 'text'], batched=True, num_proc=4)\n",
    "\n",
    "# Set dataset format for PyTorch\n",
    "dataset_enc.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Check the output\n",
    "print(dataset_enc[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba669047-db5c-4749-88d8-596e2f474420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
